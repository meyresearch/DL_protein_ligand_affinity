{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35a61cca",
   "metadata": {},
   "source": [
    "### Processing the DAVIS and KIBA datasets\n",
    "#### <span style=\"color:blue\">This notebook is for processing the data to obtain proteins whose length<\\=1024 and accordingly remove binding interactions from the dataset with protein targets above 1024 sequence length.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b6c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle,urllib\n",
    "import ast,json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c69075",
   "metadata": {},
   "source": [
    "### Select the dataset and provide the path to \"proteins.txt\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95e9b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(\"/data/davis/proteins.txt\",\"r\")\n",
    "contents=file.read()\n",
    "protein_data=ast.literal_eval(contents)\n",
    "protein_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1c818e",
   "metadata": {},
   "source": [
    "### From the available proteins, select the proteins<=1024 and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf611f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "upd_protein_data = dict()\n",
    "for (key, value) in protein_data.items():\n",
    "    if len(value)<=1024:\n",
    "        upd_protein_data[key] = value\n",
    "print(upd_protein_data)\n",
    "f = open(\"/data/davis/proteins_updated.txt\",\"w\")\n",
    "f.write( str(upd_protein_data) )\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d578455c",
   "metadata": {},
   "source": [
    "### Remove binding interactions with protein targets >1024 and save the groundtruth file of the updated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec427f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=pickle.load(open(\"/data/davis/Y\", \"rb\"), encoding='latin1')\n",
    "list_keys= list(set(protein_data.keys()) - set(upd_protein_data.keys()))\n",
    "df = pd.DataFrame(Y,  columns=list(protein_data.keys()))\n",
    "df2=df.drop(list_keys, axis = 1)\n",
    "#df.to_csv('/data/davis/davis.csv', index=False) #original\n",
    "df2.to_csv('/data/davis/davis_updated.csv', index=False) #updates davis dataset\n",
    "Y_updated=df2.to_numpy()\n",
    "np.save('/data/davis/Y_updated.npy',Y_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79537b8b",
   "metadata": {},
   "source": [
    "### Divide the available data into 6 parts- 5 for training+validation and 1 for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba85da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full=np.where(np.isnan(Y_updated.flatten())==False)[0]#Total interactions\n",
    "samples=[i for i in range(0,data_full)]\n",
    "def partition(list_in,n):\n",
    "    random.shuffle(list_in)\n",
    "    return [list_in[i::n] for i in range(n)]\n",
    "parts_6=partition(samples,6)\n",
    "with open('/data/davis/folds/train_fold_setting2.txt','w') as train_file: #saving the 5 parts as training fold\n",
    "    json.dump(parts_6[0:5],train_file)\n",
    "with open('/Users/rohan/Desktop/DTI_setup/data/davis/folds/test_fold_setting2.txt','w') as test_file: #test fold\n",
    "    json.dump(parts_6[5],test_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5154fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
