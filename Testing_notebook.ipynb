{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d665bd",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9436e104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from gnn import GNNNet\n",
    "from utils import *\n",
    "from emetrics import *\n",
    "from data import create_dataset_for_train,create_dataset_for_test,create_dataset_for_test_bootstrap\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import DataLoader\n",
    "import rdkit as rd\n",
    "from torch_sparse import SparseTensor,transpose\n",
    "import deepchem\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a703d90b",
   "metadata": {},
   "source": [
    "### Loading the dataset- Davis [0] or KIBA [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73479bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['davis', 'kiba'][0]\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2d1068",
   "metadata": {},
   "source": [
    "### Select the ligand encoding method and contact map method for protein encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0045719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#protein contact map technique\n",
    "method=['pconsc4', 'esm_cmaps', 'alpha_fold_cmaps','rand_cmaps'][0]\n",
    "method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5008db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ligand encoding method\n",
    "method1=['original','point_random', \"random_node\",'random_sample'][0]\n",
    "method1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e38a90",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cffab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicting(model, device, loader):\n",
    "    model.eval()\n",
    "    total_preds = torch.Tensor()\n",
    "    total_labels = torch.Tensor()\n",
    "    print('Make prediction for {} samples...'.format(len(loader.dataset)))\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data_mol = data[0].to(device)\n",
    "            data_pro = data[1].to(device)\n",
    "            # data = data.to(device)\n",
    "            output = model(data_mol, data_pro)\n",
    "            total_preds = torch.cat((total_preds, output.cpu()), 0)\n",
    "            total_labels = torch.cat((total_labels, data_mol.y.view(-1, 1).cpu()), 0)\n",
    "    return total_labels.numpy().flatten(), total_preds.numpy().flatten()\n",
    "\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = torch.load(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "def calculate_metrics(Y, P, dataset,result_file_name):\n",
    "    # aupr = get_aupr(Y, P)\n",
    "    cindex = get_cindex(Y, P)  # DeepDTA\n",
    "    cindex2 = get_ci(Y, P)  # GraphDTA\n",
    "    rm2 = get_rm2(Y, P)  # DeepDTA\n",
    "    mse = get_mse(Y, P)\n",
    "    pearson = get_pearson(Y, P)\n",
    "    spearman = get_spearman(Y, P)\n",
    "    rmse = get_rmse(Y, P)\n",
    "\n",
    "    print('metrics for ', dataset)\n",
    "    # print('aupr:', aupr)\n",
    "    print('cindex:', cindex)\n",
    "    print('cindex2', cindex2)\n",
    "    print('rm2:', rm2)\n",
    "    print('mse:', mse)\n",
    "    print('pearson', pearson)\n",
    "\n",
    "    result_file_name = result_file_name\n",
    "    result_str = ''\n",
    "    result_str += dataset + '\\r\\n'\n",
    "    result_str += 'rmse:' + str(rmse) + ' ' + ' mse:' + str(mse) + ' ' + ' pearson:' + str(\n",
    "        pearson) + ' ' + 'spearman:' + str(spearman) + ' ' + 'ci:' + str(cindex) + ' ' + 'rm2:' + str(rm2)\n",
    "    print(result_str)\n",
    "    open(result_file_name, 'w').writelines(result_str)\n",
    "\n",
    "\n",
    "def plot_density(Y, P, fold=0, dataset='davis'):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.grid(linestyle='--')\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    plt.scatter(P, Y, color='blue', s=40)\n",
    "    plt.title('density of ' + dataset, fontsize=30, fontweight='bold')\n",
    "    plt.xlabel('predicted', fontsize=30, fontweight='bold')\n",
    "    plt.ylabel('measured', fontsize=30, fontweight='bold')\n",
    "    # plt.xlim(0, 21)\n",
    "    # plt.ylim(0, 21)\n",
    "    if dataset == 'davis':\n",
    "        plt.plot([5, 11], [5, 11], color='black')\n",
    "    else:\n",
    "        plt.plot([6, 16], [6, 16], color='black')\n",
    "    # plt.legend()\n",
    "    plt.legend(loc=0, numpoints=1)\n",
    "    leg = plt.gca().get_legend()\n",
    "    ltext = leg.get_texts()\n",
    "    plt.setp(ltext, fontsize=12, fontweight='bold')\n",
    "    #plt.savefig(os.path.join('results', dataset + '_pconcs4_188_2000_' + str(fold) + '.png'), dpi=500, bbox_inches='tight')\n",
    "\n",
    "def calculate_metrics1(Y, P, dataset):\n",
    "    # aupr = get_aupr(Y, P)\n",
    "    cindex = get_cindex(Y, P)  # DeepDTA\n",
    "    cindex2 = get_ci(Y, P)  # GraphDTA\n",
    "    rm2 = get_rm2(Y, P)  # DeepDTA\n",
    "    mse = get_mse(Y, P)\n",
    "    pearson = get_pearson(Y, P)\n",
    "    spearman = get_spearman(Y, P)\n",
    "    rmse = get_rmse(Y, P)\n",
    "\n",
    "    print('metrics for ', dataset)\n",
    "    # print('aupr:', aupr)\n",
    "    print('cindex:', cindex)\n",
    "    print('cindex2', cindex2)\n",
    "    print('rm2:', rm2)\n",
    "    print('mse:', mse)\n",
    "    print('pearson', pearson)\n",
    "    return cindex,pearson,rmse,mse,rm2,spearman\n",
    "\n",
    "\n",
    "def calculate_metrics2(Y, P):\n",
    "    # aupr = get_aupr(Y, P)\n",
    "    cindex = get_cindex(Y, P)  # DeepDTA\n",
    "    cindex2 = get_ci(Y, P)  # GraphDTA\n",
    "    rm2 = get_rm2(Y, P)  # DeepDTA\n",
    "    mse = get_mse(Y, P)\n",
    "    pearson = get_pearson(Y, P)\n",
    "    spearman = get_spearman(Y, P)\n",
    "    rmse = get_rmse(Y, P)\n",
    "\n",
    "    \n",
    "    # print('aupr:', aupr)\n",
    "    print('cindex:', cindex)\n",
    "    print('cindex2', cindex2)\n",
    "    print('rm2:', rm2)\n",
    "    print('mse:', mse)\n",
    "    print('pearson', pearson)\n",
    "    return cindex,pearson,rmse,mse,rm2,spearman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e11117",
   "metadata": {},
   "source": [
    "### Loading the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39016d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#If CUDA is available\n",
    "cuda_name = ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'][0]\n",
    "device = torch.device(cuda_name)\n",
    "TEST_BATCH_SIZE = 128\n",
    "\n",
    "#Loading the path to the trained model and setting the results path\n",
    "model_file_name = 'models_sample/model_pconsc4_GNNNet_random_node_kiba_random_node_0.model'\n",
    "result_file_name = 'results6/result_kiba_random_node_0_'+ '.txt'\n",
    "model = GNNNet()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(model_file_name, map_location=cuda_name))\n",
    "\n",
    "#Loading the test data\n",
    "test_data = create_dataset_for_test(str(datasets),method,method1)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=TEST_BATCH_SIZE, shuffle=False,\n",
    "                                              collate_fn=collate)\n",
    "\n",
    "#predictions using the trained model\n",
    "Y, P = predicting(model, device, test_loader)\n",
    "calculate_metrics(Y, P, str(datasets),result_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b16b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#If CUDA is available\n",
    "cuda_name = ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'][0]\n",
    "device = torch.device(cuda_name)\n",
    "\n",
    "\n",
    "#Loading the path to the trained model and setting the results path\n",
    "model_file_name = 'models_sample/model_pconsc4_GNNNet_random_davis_2.model'\n",
    "result_file_name = 'results33/result_davis_pconcs4_random_2_'+ '.txt'\n",
    "model = GNNNet()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(model_file_name, map_location=cuda_name))\n",
    "\n",
    "#Loading the test data\n",
    "test_data = create_dataset_for_test(str(datasets),method,method1)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=TEST_BATCH_SIZE, shuffle=False,\n",
    "                                              collate_fn=collate)\n",
    "\n",
    "#predictions using the trained model\n",
    "Y1, P1 = predicting(model, device, test_loader)\n",
    "calculate_metrics(Y1, P1, str(datasets),result_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db5e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#If CUDA is available\n",
    "cuda_name = ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'][0]\n",
    "device = torch.device(cuda_name)\n",
    "\n",
    "\n",
    "#Loading the path to the trained model and setting the results path\n",
    "model_file_name = 'models_sample/model_pconsc4_GNNNet_random_davis_4.model'\n",
    "result_file_name = 'results33/result_davis_pconcs4_random_4_'+ '.txt'\n",
    "model = GNNNet()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(model_file_name, map_location=cuda_name))\n",
    "\n",
    "#Loading the test data\n",
    "test_data = create_dataset_for_test(str(datasets),method,method1)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=TEST_BATCH_SIZE, shuffle=False,\n",
    "                                              collate_fn=collate)\n",
    "\n",
    "#predictions using the trained model\n",
    "Y2, P2 = predicting(model, device, test_loader)\n",
    "calculate_metrics(Y2, P2, str(datasets),result_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658883b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = [np.mean(k) for k in zip(P,P1,P2)]\n",
    "res1 = [np.std(k) for k in zip(P,P1,P2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d48428",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'exp': Y, 'model1': P,'model2': P1,'model3': P2,'mean': res,'std': res1}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9195c02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results_figures/pconcs4_random_davis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dd8075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf1d0e6b",
   "metadata": {},
   "source": [
    "### Bootstrapping the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c84cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('results_figures/pconsc4_original_davis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f41544",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56181740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bootstrapping the test data \n",
    "rmse1=[]\n",
    "pearson1=[]\n",
    "ci1=[]\n",
    "mse1=[]\n",
    "rm1=[]\n",
    "spearman1=[]\n",
    "niters=40\n",
    "\n",
    "for i in range(niters):\n",
    "    rmse1a=[]\n",
    "    pearson1a=[]\n",
    "    ci1a=[]\n",
    "    mse1a=[]\n",
    "    rm1a=[]\n",
    "    spearman1a=[]\n",
    "    df2 = df.sample(n=1000)\n",
    "    Y=np.array(df2['exp'])\n",
    "    P1=np.array(df2['model1'])\n",
    "    P2=np.array(df2['model2'])\n",
    "    P3=np.array(df2['model3'])\n",
    "    \n",
    "    cindex,pearson,rmse,mse,rm2,spearman=calculate_metrics2(Y, P1)\n",
    "    ci1a.append(cindex)\n",
    "    pearson1a.append(pearson)\n",
    "    rmse1a.append(rmse)\n",
    "    mse1a.append(mse)\n",
    "    rm1a.append(rm2)\n",
    "    spearman1a.append(spearman)\n",
    "\n",
    "    cindex,pearson,rmse,mse,rm2,spearman=calculate_metrics2(Y, P2)\n",
    "    ci1a.append(cindex)\n",
    "    pearson1a.append(pearson)\n",
    "    rmse1a.append(rmse)\n",
    "    mse1a.append(mse)\n",
    "    rm1a.append(rm2)\n",
    "    spearman1a.append(spearman)\n",
    "    \n",
    "    cindex,pearson,rmse,mse,rm2,spearman=calculate_metrics2(Y, P3)\n",
    "    ci1a.append(cindex)\n",
    "    pearson1a.append(pearson)\n",
    "    rmse1a.append(rmse)\n",
    "    mse1a.append(mse)\n",
    "    rm1a.append(rm2)\n",
    "    spearman1a.append(spearman)\n",
    "\n",
    "    \n",
    "    ci1.append(np.mean(ci1a))\n",
    "    pearson1.append(np.mean(pearson1a))\n",
    "    rmse1.append(np.mean(rmse1a))\n",
    "    mse1.append(np.mean(mse1a))\n",
    "    rm1.append(np.mean(rm1a))\n",
    "    spearman1.append(np.mean(spearman1a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de8a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pearson1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1065f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmaps=['Original Ligand Graph']*40\n",
    "cmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51fe050",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'CI': ci1, 'Pearson': pearson1,'RMSE': rmse1,'Spearman': spearman1,'cmap':cmaps}\n",
    "df_res = pd.DataFrame(data=d)\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c734b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.to_csv('results_figures/pconcs4_original_ligand_davis_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769184cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
