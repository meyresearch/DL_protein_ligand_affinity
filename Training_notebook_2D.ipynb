{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e43dd1f",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390123a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from utils import *\n",
    "from emetrics import *\n",
    "from data import create_dataset_for_train\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import DataLoader\n",
    "import rdkit as rd\n",
    "from torch_sparse import SparseTensor,transpose\n",
    "import deepchem\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from dnn import GNNNet,GNNNet_prod,GNNNet_prod_conc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c83e081",
   "metadata": {},
   "source": [
    "### Loading the dataset- Davis [0] or KIBA [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895d1b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [['davis', 'kiba'][0]]\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f05743",
   "metadata": {},
   "source": [
    "### Select the ligand encoding method and contact map method for protein encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc53b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#protein contact map technique\n",
    "method=['pconsc4', 'esm_cmaps', 'alpha_fold_cmaps','rand_cmaps'][0]\n",
    "method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ea6791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ligand encoding method\n",
    "method1=['original','point_random', \"random_node\",'random_sample'][0]\n",
    "method1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a87c1b",
   "metadata": {},
   "source": [
    "### Select the method to combine the encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a67e3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb=['conc','prod','conc+prod'][0]\n",
    "\n",
    "if comb=='conc':\n",
    "    model = GNNNet()\n",
    "elif comb=='prod':\n",
    "    model = GNNNet_prod()\n",
    "elif comb=='conc+prod':\n",
    "    model = GNNNet_prod_conc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bb041b",
   "metadata": {},
   "source": [
    "### Initialising the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15b7828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the GNN model for generating the embedding\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#If CUDA is available\n",
    "cuda_name = ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'][0]\n",
    "device = torch.device(cuda_name)\n",
    "model.to(device)\n",
    "model_st = GNNNet.__name__\n",
    "fold = [0, 1, 2, 3, 4][0]\n",
    "#Setting the path to save the trained model\n",
    "models_dir = 'models'\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f438d8a6",
   "metadata": {},
   "source": [
    "### Hyperparameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e194c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 128\n",
    "TEST_BATCH_SIZE = 128\n",
    "LR = 0.001 #Learning Rate\n",
    "NUM_EPOCHS = 2000 #No.of Epochs\n",
    "loss_fn = nn.MSELoss() # Loss function - MSE\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR) #Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e27f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    train_data, valid_data = create_dataset_for_train(dataset, fold, method,method1)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=TRAIN_BATCH_SIZE, shuffle=True,\n",
    "                                               collate_fn=collate)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=TEST_BATCH_SIZE, shuffle=False,\n",
    "                                               collate_fn=collate)\n",
    "\n",
    "    best_mse = 1000\n",
    "    best_test_mse = 1000\n",
    "    best_epoch = -1\n",
    "    #Set the model file name\n",
    "    model_file_name = 'models_sample/model_'+ method + '_'+ model_st + '_' +method1 + '_'+ dataset + '_random_node_' + str(fold) +'.model'\n",
    "    print(model_file_name)\n",
    "    mse_list1=[]\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train(model, device, train_loader, optimizer, epoch + 1)\n",
    "        print('predicting for valid data')\n",
    "        G, P = predicting(model, device, valid_loader)\n",
    "        val = get_mse(G, P)\n",
    "        mse_list1.append(val)\n",
    "        print('valid result:', val, best_mse)\n",
    "        if val < best_mse:\n",
    "            best_mse = val\n",
    "            best_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), model_file_name)\n",
    "            print('rmse improved at epoch ', best_epoch, '; best_test_mse', best_mse, model_st, dataset, fold)\n",
    "        else:\n",
    "            print('No improvement since epoch ', best_epoch, '; best_test_mse', best_mse, model_st, dataset, fold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b13f94e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edd282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mse_davis_pconcs4_random_node_3.txt', 'w') as f:\n",
    "    for item in mse_list1:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550ff1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ep=[i for i in range(1,2001)]\n",
    "\n",
    "plt.plot(ep,mse_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebed4657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
