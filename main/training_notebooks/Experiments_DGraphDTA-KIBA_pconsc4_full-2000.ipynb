{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c72175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from gnn import GNNNet\n",
    "from utils import *\n",
    "from emetrics import *\n",
    "from data_process import create_dataset_for_5folds\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import DataLoader\n",
    "import rdkit as rd\n",
    "from torch_sparse import SparseTensor,transpose\n",
    "import deepchem\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf7ae2b",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b30c8d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kiba']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = [['davis', 'kiba'][1]]\n",
    "datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6280388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pconsc4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method=['pconsc4', 'esm_cmaps', 'alpha_fold_cmaps'][0]\n",
    "method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91bfc268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda_name: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.device('cuda:0')\n",
    "cuda_name = ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'][0]\n",
    "print('cuda_name:', cuda_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "463631d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epochs:  1500\n"
     ]
    }
   ],
   "source": [
    "fold = [0, 1, 2, 3, 4][0]\n",
    "cross_validation_flag = True\n",
    "# print(int(sys.argv[3]))\n",
    "\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "TEST_BATCH_SIZE = 128\n",
    "LR = 0.001\n",
    "NUM_EPOCHS = 1500\n",
    "\n",
    "print('Learning rate: ', LR)\n",
    "print('Epochs: ', NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b84c5a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNNet Loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models_dir = 'models_sample'\n",
    "results_dir = 'results'\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "# Main program: iterate over different datasets\n",
    "result_str = ''\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(cuda_name)\n",
    "model_file_name = 'models_sample/model_kiba_pconsc4_500_GNNNet_kiba_0.model'\n",
    "model = GNNNet()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(model_file_name, map_location=cuda_name))\n",
    "# model = GNNNet()\n",
    "# model=model_kiba_esm__188_500_GNNNet_kiba_1.model\n",
    "#model.to(device)\n",
    "model_st = GNNNet.__name__\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38408c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: kiba\n",
      "fold: 0\n",
      "train entries: 78836 effective train entries 78717\n",
      "valid entries: 19709 effective valid entries 19685\n",
      "effective drugs,effective prot: 2068 228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/scratch/DGraphDTA/utils.py:52: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  GCNData_mol = DATA.Data(x=torch.Tensor(features),\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    train_data, valid_data = create_dataset_for_5folds(dataset, fold, method)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=TRAIN_BATCH_SIZE, shuffle=True,\n",
    "                                               collate_fn=collate)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=TEST_BATCH_SIZE, shuffle=False,\n",
    "                                               collate_fn=collate)\n",
    "\n",
    "    best_mse = 1000\n",
    "    best_test_mse = 1000\n",
    "    best_epoch = -1\n",
    "    model_file_name = 'models_sample/model_kiba_pconsc4_full_2000_' + model_st + '_' + dataset + '_' + str(fold) + '.model'\n",
    "    mse_list1=[]\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train(model, device, train_loader, optimizer, epoch + 1)\n",
    "        print('predicting for valid data')\n",
    "        G, P = predicting(model, device, valid_loader)\n",
    "        val = get_mse(G, P)\n",
    "        mse_list1.append(val)\n",
    "        print('valid result:', val, best_mse)\n",
    "        if val < best_mse:\n",
    "            best_mse = val\n",
    "            best_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), model_file_name)\n",
    "            print('rmse improved at epoch ', best_epoch, '; best_test_mse', best_mse, model_st, dataset, fold)\n",
    "        else:\n",
    "            print('No improvement since epoch ', best_epoch, '; best_test_mse', best_mse, model_st, dataset, fold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e24fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ep=[i for i in range(1,1501)]\n",
    "\n",
    "plt.plot(ep,mse_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73354fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mse_pconcs4_full_2000_file.txt', 'w') as f:\n",
    "    for item in mse_list1:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5cd571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1736084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold_origin = json.load(open('data/kiba/' + 'folds/train_fold_setting1.txt'))\n",
    "train_fold_origin = [e for e in train_fold_origin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ed8443",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7de995",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_fold_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936e4bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fold_origin = json.load(open('data/kiba/' + 'folds/test_fold_setting1.txt'))\n",
    "test_fold_origin = [e for e in test_fold_origin]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb90116",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(test_fold_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a918da0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in train_fold_origin for item in sublist]\n",
    "flat_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224c0c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c012c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(flat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559c617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(flat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ef355",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18db1ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_fold_origin[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20eeb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold_origin[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1e2ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/kiba/kiba_1024.txt') as f:\n",
    "    lines = f.readlines()\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2080240",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/kiba/kiba_1024.txt', \"r\") as fd:\n",
    "    lines = fd.read().splitlines()\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe61229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff964ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "affinity = pickle.load(open( 'data/kiba/'+ 'Y', 'rb'), encoding='latin1')\n",
    "affinity = np.asarray(affinity)\n",
    "affinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcc1c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "affinity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddedc3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "affinity2 = np.load(open('data/kiba/' + 'Y_updated.npy', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bff32d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "affinity2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aeb1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "affinity2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6d435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(np.isnan(affinity2.flatten()) == False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81364574",
   "metadata": {},
   "outputs": [],
   "source": [
    "2111*229"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4044489",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_aff=affinity.flatten()\n",
    "len(flat_aff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0232c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(np.isnan(flat_aff) == False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd7c8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df4=pd.read_csv('data/kiba/kiba.csv')  \n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f00650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbbba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4799d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df4.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774343ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(df4.index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095bf5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fb0085",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e037eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efee1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df4 = df4.set_index('Unnamed: 0')\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1db18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "file = open(\"data/kiba/ligands_can.txt\", \"r\")\n",
    "\n",
    "contents = file.read()\n",
    "ligands = ast.literal_eval(contents)\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(type(ligands))\n",
    "\n",
    "\n",
    "print(ligands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6977bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ligands.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cbf791",
   "metadata": {},
   "outputs": [],
   "source": [
    "kiba_p.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c725e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins_upd=kiba_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd6d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(proteins_upd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbedc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "  \n",
    "with open(\"data/kiba/proteins_updated.txt\", 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(proteins_upd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09024edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lines:\n",
    "    del proteins_upd[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0723a0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ligands.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03a75dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "file = open(\"data/kiba/proteins.txt\", \"r\")\n",
    "\n",
    "contents = file.read()\n",
    "kiba_p = ast.literal_eval(contents)\n",
    "\n",
    "file.close()\n",
    "\n",
    "print(type(kiba_p))\n",
    "\n",
    "\n",
    "print(kiba_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f9e741",
   "metadata": {},
   "outputs": [],
   "source": [
    "kiba_p.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73785fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f24f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "file = open('data/kiba/kiba.csv')\n",
    "csvreader = csv.reader(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ec7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2=set(kiba_p.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9507899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ligand.ke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5ba91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(set(header))-list(set(kiba_p.keys()))\n",
    "s = set(np.unique(df4.columns))\n",
    "temp3 = [x for x in s if x not in t2]\n",
    "np.sort(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32b1075",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = set(np.unique(df4.index.values))\n",
    "temp4 = [x for x in s if x not in list(ligands.keys())]\n",
    "np.sort(temp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f45bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee11eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=df4.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ab1d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1153a77f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91380a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6_a=df6.drop(labels=lines,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0203367e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a270eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3c87d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=df6.drop(labels=temp3,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e28ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=df6.drop(labels=temp4,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a480d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7c1787",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(np.isnan(df6_a.to_numpy().flatten()) == False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5de90b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full=np.where(np.isnan(df6_a.to_numpy().flatten()) == False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4124504",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.isnan(df6_a.to_numpy().flatten()) == False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a73d67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(data_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca05b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "95574/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4411466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=[i for i in range(0,95574)]\n",
    "len(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af247b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ad4641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "def partition (list_in, n):\n",
    "    random.shuffle(list_in)\n",
    "    return [list_in[i::n] for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea69512",
   "metadata": {},
   "outputs": [],
   "source": [
    "parts_6=partition(samples,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9201981e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b2d6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/kiba/folds/train_fold_setting2.txt','w') as myfile:\n",
    "    json.dump(parts_6,myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d3c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "parts_test=parts_6[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0ede12",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/kiba/folds/test_fold_setting2.txt', 'w') as temp_file:\n",
    "    json.dump(parts_test,temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c188c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(parts_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e5cec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(parts_6[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a7d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold_origin = json.load(open('data/kiba/' + 'folds/train_fold_setting1.txt'))\n",
    "train_fold_origin = [e for e in train_fold_origin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29912e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816619e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.to_csv('/disk/scratch/DGraphDTA/data/kiba/main.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27efc84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(d6, open(\"/disk/scratch/DGraphDTA/data/kiba/main.pkl\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7e843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/disk/scratch/DGraphDTA/data/kiba/Y_updated\",df6_a.to_numpy(),allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16124b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aea564",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59f914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "174+229"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = []\n",
    "header = next(csvreader)\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85924f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "118254-19709*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9b714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.isnan(affinity) == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd1e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = np.where(np.isnan(affinity) == False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c92f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = rows[train_folds], cols[train_folds]\n",
    "            train_fold_entries = []\n",
    "            for pair_ind in range(len(rows)):\n",
    "                if not valid_target(prot_keys[cols[pair_ind]], dataset):  # ensure the contact and aln files exists\n",
    "                    continue\n",
    "                ls = []\n",
    "                ls += [drugs[rows[pair_ind]]]\n",
    "                ls += [prots[cols[pair_ind]]]\n",
    "                ls += [prot_keys[cols[pair_ind]]]\n",
    "                ls += [affinity[rows[pair_ind], cols[pair_ind]]]\n",
    "                train_fold_entries.append(ls)\n",
    "                valid_train_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84b1f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [['davis', 'kiba'][1]]\n",
    "datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc23c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9115a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.device('cuda:0')\n",
    "cuda_name = ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'][0]\n",
    "print('cuda_name:', cuda_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855f415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = [0, 1, 2, 3, 4][0]\n",
    "cross_validation_flag = True\n",
    "# print(int(sys.argv[3]))\n",
    "\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "TEST_BATCH_SIZE = 128\n",
    "LR = 0.001\n",
    "NUM_EPOCHS = 500\n",
    "\n",
    "print('Learning rate: ', LR)\n",
    "print('Epochs: ', NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0fcac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = 'models_sample'\n",
    "results_dir = 'results'\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "# Main program: iterate over different datasets\n",
    "result_str = ''\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(cuda_name)\n",
    "model = GNNNet()\n",
    "model.to(device)\n",
    "model_st = GNNNet.__name__\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930c2136",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    train_data, valid_data = create_dataset_for_5folds(dataset, fold)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=TRAIN_BATCH_SIZE, shuffle=True,\n",
    "                                               collate_fn=collate)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=TEST_BATCH_SIZE, shuffle=False,\n",
    "                                               collate_fn=collate)\n",
    "\n",
    "    best_mse = 1000\n",
    "    best_test_mse = 1000\n",
    "    best_epoch = -1\n",
    "    model_file_name = 'models_sample/model_kiba_pconsc4_500_' + model_st + '_' + dataset + '_' + str(fold) + '.model'\n",
    "    mse_list1=[]\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train(model, device, train_loader, optimizer, epoch + 1)\n",
    "        print('predicting for valid data')\n",
    "        G, P = predicting(model, device, valid_loader)\n",
    "        val = get_mse(G, P)\n",
    "        mse_list1.append(val)\n",
    "        print('valid result:', val, best_mse)\n",
    "        if val < best_mse:\n",
    "            best_mse = val\n",
    "            best_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), model_file_name)\n",
    "            print('rmse improved at epoch ', best_epoch, '; best_test_mse', best_mse, model_st, dataset, fold)\n",
    "        else:\n",
    "            print('No improvement since epoch ', best_epoch, '; best_test_mse', best_mse, model_st, dataset, fold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2f4496",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5671b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c7c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16518858",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t,r,a,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6333757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t,r,a,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2119de4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.mem_get_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d90f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8d09a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796d04a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ep=[i for i in range(1,501)]\n",
    "\n",
    "plt.plot(ep,mse_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e72db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mse_pconsc4_500_file.txt', 'w') as f:\n",
    "    for item in mse_list1:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d856df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "from emetrics import get_aupr, get_cindex, get_rm2, get_ci, get_mse, get_rmse, get_pearson, get_spearman\n",
    "from utils import *\n",
    "from scipy import stats\n",
    "from gnn import GNNNet\n",
    "from data_process import create_dataset_for_test\n",
    "\n",
    "\n",
    "def predicting(model, device, loader):\n",
    "    model.eval()\n",
    "    total_preds = torch.Tensor()\n",
    "    total_labels = torch.Tensor()\n",
    "    print('Make prediction for {} samples...'.format(len(loader.dataset)))\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data_mol = data[0].to(device)\n",
    "            data_pro = data[1].to(device)\n",
    "            # data = data.to(device)\n",
    "            output = model(data_mol, data_pro)\n",
    "            total_preds = torch.cat((total_preds, output.cpu()), 0)\n",
    "            total_labels = torch.cat((total_labels, data_mol.y.view(-1, 1).cpu()), 0)\n",
    "    return total_labels.numpy().flatten(), total_preds.numpy().flatten()\n",
    "\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = torch.load(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "def calculate_metrics(Y, P, dataset='davis'):\n",
    "    # aupr = get_aupr(Y, P)\n",
    "    cindex = get_cindex(Y, P)  # DeepDTA\n",
    "    cindex2 = get_ci(Y, P)  # GraphDTA\n",
    "    rm2 = get_rm2(Y, P)  # DeepDTA\n",
    "    mse = get_mse(Y, P)\n",
    "    pearson = get_pearson(Y, P)\n",
    "    spearman = get_spearman(Y, P)\n",
    "    rmse = get_rmse(Y, P)\n",
    "\n",
    "    print('metrics for ', dataset)\n",
    "    # print('aupr:', aupr)\n",
    "    print('cindex:', cindex)\n",
    "    print('cindex2', cindex2)\n",
    "    print('rm2:', rm2)\n",
    "    print('mse:', mse)\n",
    "    print('pearson', pearson)\n",
    "\n",
    "    result_file_name = 'results/result_pconsc4_500_' + model_st + '_' + dataset + '.txt'\n",
    "    result_str = ''\n",
    "    result_str += dataset + '\\r\\n'\n",
    "    result_str += 'rmse:' + str(rmse) + ' ' + ' mse:' + str(mse) + ' ' + ' pearson:' + str(\n",
    "        pearson) + ' ' + 'spearman:' + str(spearman) + ' ' + 'ci:' + str(cindex) + ' ' + 'rm2:' + str(rm2)\n",
    "    print(result_str)\n",
    "    open(result_file_name, 'w').writelines(result_str)\n",
    "\n",
    "\n",
    "def plot_density(Y, P, fold=0, dataset='davis'):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.grid(linestyle='--')\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    plt.scatter(P, Y, color='blue', s=40)\n",
    "    plt.title('density of ' + dataset, fontsize=30, fontweight='bold')\n",
    "    plt.xlabel('predicted', fontsize=30, fontweight='bold')\n",
    "    plt.ylabel('measured', fontsize=30, fontweight='bold')\n",
    "    # plt.xlim(0, 21)\n",
    "    # plt.ylim(0, 21)\n",
    "    if dataset == 'davis':\n",
    "        plt.plot([5, 11], [5, 11], color='black')\n",
    "    else:\n",
    "        plt.plot([6, 16], [6, 16], color='black')\n",
    "    # plt.legend()\n",
    "    plt.legend(loc=0, numpoints=1)\n",
    "    leg = plt.gca().get_legend()\n",
    "    ltext = leg.get_texts()\n",
    "    plt.setp(ltext, fontsize=12, fontweight='bold')\n",
    "    plt.savefig(os.path.join('results', dataset + '_pconsc4_500_' + str(fold) + '.png'), dpi=500, bbox_inches='tight')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fd5fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = ['davis', 'kiba'][1]  # dataset selection\n",
    "model_st = GNNNet.__name__\n",
    "print('dataset:', dataset)\n",
    "cuda_name = ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'][0] # gpu selection\n",
    "print('cuda_name:', cuda_name)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb02c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_BATCH_SIZE = 128\n",
    "models_dir = 'models'\n",
    "results_dir = 'results'\n",
    "\n",
    "device = torch.device(cuda_name if torch.cuda.is_available() else 'cpu')\n",
    "#model_file_name = 'models_sample/model1111_' + model_st + '_' + dataset + '.model'\n",
    "model_file_name = 'models_sample/model_kiba_pconsc4_500_GNNNet_kiba_0.model'\n",
    "result_file_name = 'results/resul_pconsc4_500_' + model_st + '_' + dataset + '.txt'\n",
    "\n",
    "model = GNNNet()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(model_file_name, map_location=cuda_name))\n",
    "test_data = create_dataset_for_test(dataset)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=TEST_BATCH_SIZE, shuffle=False,\n",
    "                                              collate_fn=collate)\n",
    "\n",
    "Y, P = predicting(model, device, test_loader)\n",
    "calculate_metrics(Y, P, dataset)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e9def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2c18ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3629398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5837dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_file = open(\"alpha500_pred_file.txt\", \"r\")\n",
    "content = my_file.read()\n",
    "content=content.splitlines()\n",
    "content=[float(i) for i in content]\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89097571",
   "metadata": {},
   "outputs": [],
   "source": [
    "P1=np.asarray(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a803e9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aae03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(P,color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af958357",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d4017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d25829",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_density(P1, P, fold, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33594e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pconsc4_500_gt_file.txt', 'w') as f:\n",
    "    for item in list(Y):\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd8ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pconsc4_500_pred_file.txt', 'w') as f:\n",
    "    for item in list(P):\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3f4d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_density(Y, P, fold, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c806893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_density1(Y, P,P1, fold=0, dataset='davis'):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.grid(linestyle='--')\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    plt.scatter(P, Y, color='blue', s=40)\n",
    "    plt.scatter(P1, Y, color='green', s=40)\n",
    "    plt.title('density of ' + dataset, fontsize=30, fontweight='bold')\n",
    "    plt.xlabel('predicted', fontsize=30, fontweight='bold')\n",
    "    plt.ylabel('measured', fontsize=30, fontweight='bold')\n",
    "    # plt.xlim(0, 21)\n",
    "    # plt.ylim(0, 21)\n",
    "    if dataset == 'davis':\n",
    "        plt.plot([5, 11], [5, 11], color='black')\n",
    "    else:\n",
    "        plt.plot([6, 16], [6, 16], color='black')\n",
    "    # plt.legend()\n",
    "    plt.legend(loc=0, numpoints=1)\n",
    "    leg = plt.gca().get_legend()\n",
    "    ltext = leg.get_texts()\n",
    "    plt.setp(ltext, fontsize=12, fontweight='bold')\n",
    "    #plt.savefig(os.path.join('results', dataset + 'alpha v/s pconsc4_500_' + str(fold) + '.png'), dpi=500, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0550ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_density1(Y, P,P1, fold, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a555926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_density(Y, P, fold, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bce1896",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_density(Y, P, fold, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12380e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc260a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2, 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5826f10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
